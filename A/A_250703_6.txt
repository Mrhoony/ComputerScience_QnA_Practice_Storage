TCP/IP 4계층이란?
->
통신 프로토콜 스택을 계층화한 것입니다. OSI 7계층 모델보다 더 실용적이고 단순화된 모델로 실제 인터넷에서 주로 사용됩니다.

[ 어플리케이션 계층 ]
사용자와 직접 상호작용하는 응용 프로그램들이 네트워크 서비스를 이용할 수 있도록 합니다. 특정 서비스를 위한 프로토콜을 정의하며 데이터의 형식과 처리 절차를 결정합니다.

단위: 데이터 또는 메세지

주요 프로토콜.
HTTP: 웹 통신
FTP: 파일 송수신
SMTP: 이메일 송신
POP3: 이메일 수신
DNS: 도메인 이름을 IP 주소로 변환
SSH: 원격 시스템 접속
Telnet: 원격 터미널 접속

[ 전송 계층 ]
출발지 호스트의 어플리케이션과 목적지 호스트의 어플리케이션 간의 논리적인 통신 연결을 설정하고 유지하며 데이터 전송의 신뢰성을 보장하거나 빠른 전송을 담당합니다. 포트 번호를 사용하여 어떤 어플리케이션으로 데이터를 전달할지 식별합니다.

단위: 세그먼트, 데이터그램

주요 프로토콜.
TCP: 연결 지향적, 신뢰성 보장(손실, 순서, 오류, 혼잡, 흐름 제어)
UDP: 비연결 지향적, 비신뢰성

[ 인터넷 계층 ]
네트워크상에서 데이터를 한 곳에서 다른 곳으로 라우팅하는 역할을 합니다. 데이터를 패킷 단위로 묶고 IP 주소를 사용하여 출발지와 목적지 간의 최적 경로를 찾아 패킷을 전달합니다. 서로 다른 네트워크 간의 통신을 가능하게 합니다.

단위: 패킷

주요 프로토콜.
IP: 데이터를 패킷 단위로 캡슐화하고 IP 주소를 기반으로 라우팅을 수행, 비연결성, 비신뢰성
ARP: IP 주소를 물리적 MAC 주소로 변환
ICMP: IP 패킷 전송 중 발생하는 오류를 알리거나 네트워크 진단에 사용
IGMP: 멀티캐스트 그룹 관리

[ 네트워크 인터페이스 계층 ]
TCP/IP 모델의 가장 하위 계층으로 실제 물리적 매체를 통해 데이터를 전기적/광학적 신호로 변환하여 전송하고 수신하는 역할을 합니다. OSI 7계층의 물리 계층과 데이터 링크 계층의 기능을 모두 포함합니다. MAC 주소를 사용하여 동일 네트워크 내에서 장치 간의 통신을 담당합니다.

단위: 프레임

주요 프로토콜 또는 기술.
Ethernet: 유선 LAN 기술 표준
Wi-Fi: 무선 네트워크 표준
MAC: 네트워크 장치에 고유하게 할당된 물리적 주소로
PPP: 두 지점 간의 직접 연결을 통한 통신

주요 장비: 허브, 스위치, NIC, 라우터의 물리적 인터페이스



가상 메모리란?
->
가상 메모리는 운영체제가 제공하는 메모리 관리 기법 중 하나로 프로세스에게 실제 물리적인 메모리의 크기보다 훨씬 더 크고 연속적인 것처럼 보이는 메모리 공간을 제공하는 기술 전반을 의미합니다.

1. 운영체제의 메모리 관리 기술 전체
가상 메모리의 핵심 목표.
물리적 메모리 한계 극복: 실제 RAM 용량의 제약을 받지 않고 프로그램 실행
다중 프로그래밍 효율성 증대: 각 프로세스마다 메모리 관리
메모리 보호: 각 프로세스에게 독립적인 가상 주소 공간을 할당
프로그래머의 편의성: 실제 RAM 다룰 필요 없이 추상화된 가상 주소 공간 이용

작동 원리.
가상 메모리는 두가지 주소 체계를 사용합니다.
가상 주소: CPU가 생성하고 프로그램이 사용, 각 프로세스는 독립적인 가상 주소 공간을 가짐
물리 주소: 실제 RAM 칩의 물리적 위치를 나타내는 주소로

이 두 주소는 MMU(Memory Management Unit)라는 하드웨어 장치와 운영체제의 페이지 테이블을 통해 실시간으로 변환됩니다. 가상 주소 공간은 보통 고정된 크기의 페이지 단위로 나뉘고 물리적 메모리 공간은 동일한 크기의 페이지 프레임 단위로 나뉩니다. 페이지 테이블은 어떤 가상 페이지가 어떤 물리적 페이지 프레임에 매핑되어 있는지 기록합니다.

2. 스왑 공간
가상 메모리 시스템의 중요한 구성 요소 중 하나가 바로 스왑 공간입니다. 이는 하드 디스크(또는 SSD)의 특정 영역을 물리적 RAM의 부족분을 보충하기 위한 보조 저장 공간으로 사용하는 것을 의미하며 종종 가상 메모리라고 지칭될 때 이 스왑 공간을 의미하는 경우가 많습니다.

스왑 공간이 필요한 이유: 아무리 많은 RAM을 가지고 있어도 모든 실행 중인 프로그램의 모든 데이터를 항상 RAM에 올려둘 수는 없습니다. 또는 당장 필요 없는 데이터는 RAM에서 잠시 내려놓음으로서 다른 더 중요한 데이터가 RAM을 사용할 수 있도록 해야합니다.

작동 방식(스와핑).
페이지 폴트 발생 시: CPU가 어떤 가상 주소에 접근하려고 했는데 해당 가상 주소에 해당하는 페이지가 현재 물리적 RAM에 없고 하드 디스크의 스왑 공간에 저장되어 있을 때 페이지 폴트가 발생합니다.
스왑 인: 운영체제는 페이지 폴트가 발생하면 해당 페이지를 스왑 공간에서 찾아 물리적 RAM의 비어있는 페이지 프레임으로 로드합니다.
스왑 아웃: 만약 RAM에 비어있는 페이지 프레임이 없다면 운영체제는 페이지 교체 알고리즘을 사용하여 현재 RAM에 있는 페이지 중 사용 빈도가 낮거나 우선순위가 낮은 페이지를 선택하여 스왑 공간으로 옮깁니다. 이 과정을 통해 RAM 공간을 확보하여 필요한 페이지를 스왑 인할 수 있게 됩니다.

하드 디스크의 일부분을 RAM처럼 사용하는 것은 가상 메모리라는 큰 개념 안에서 물리적 RAM의 한계를 보완하기 위한 보조 저장소 역할로서의 스왑 공간을 활용하는 것입니다.

결론.
가상 메모리란: 프로세스에게 추상화되고 확장된 메모리 공간을 제공하는 운영체제의 메모리 관리 기술 전체
가상 메모리란: 가상 메모리 기술의 한 부분으로 물리적 RAM 부족 시 사용되는 하드 디스크의 스왑 공간

근본적으로 스왑 공간은 가상 메모리 시스템이라는 큰 틀 안에서 물리적 RAM의 보조 역할을 수행하는 구성요소입니다.



운영체제의 스케줄링이란?
->
운영체제의 스케줄링은 컴퓨터 시스템의 자원을 여러 프로세스 또는 스레드에게 어떻게 할당할 것인지 결정하는 일련의 과정입니다. 다중 프로그래밍 환경에서 CPU의 활용도를 높이고 사용자에게는 여러 프로그램이 동시에 실행되는 것처럼 보이게 하는 핵심 기능입니다.

스케줄링이 필요한 이유.
CPU 활용 극대화
응답 시간 최소화
처리량 최대화
대기 시간 최소화
공정성

스케줄링의 종류.
장기 스케줄링: 작업 큐(디스크)에 있는 작업(프로그램) 중 어떤 것을 준비 큐(메모리)로 로드할지 결정
단기 스케줄링: 준비 큐(메모리)에 있는 프로세스(또는 스레드) 중 어떤 것에 CPU를 할당할지 결정
중기 스케줄링: 메모리나 스왑 공간에서의 프로세스에 대한 스왑 인/아웃 결정

CPU 스케줄링 알고리즘.
선입선출(First-Com First-Served, FCFS)
원리: CPU를 먼저 요청한 프로세스가 CPU 할당받음
장점: 구현 간단
단점: 호그 현상(Convoy Effect, 긴 작업이 들어오면 뒤의 짧은 작업들이 오래 기다림) 발생 가능

최단 작업 우선(Shortest-Job-First, SJF)
원리: CPU 버스트 시간이 가장 짧은 프로세스에게 CPU 할당
장점: 평균 대기 시간이 가장 짧음
단점: 기아 현상(긴 작업은 무한정 대기할 수 있음) 발생 가능

우선순위 스케줄링(Priority Scheduling)
원리: 각 프로세스에 우선순위 부여, 가장 높은 우선순위의 프로세스에게 CPU 할당
장점: 중요한 작업 빠르게 처리
단점: 낮은 우선순위의 작업이 CPU를 할당받지 못하는 기아 현상 발생 가능 -> 에이징 기법으로 보완(시간이 지날수록 우선순위를 높여줌)

라운드 로빈(Round Robin, RR)
원리: 각 프로세스에게 타임 슬라이스 또는 퀀텀이라는 고정된 시간 할당량을 부여하고 시간이 만료되면 CPU를 빼앗아 다음 프로세스에게 할당
장점: 모든 프로세스에게 공정한 기회 제공
단점: 컨텍스트 스위칭 오버헤드 발생

다단계 큐(Multilevel Queue)
원리: 프로세스들을 특성에 따라 여러개의 준비 큐로 나눔, 각 큐는 자신만의 스케줄링 알고리즘 가짐
장점: 다양한 유형의 프로세스를 효율적으로 관리
단점: 큐 간에 고정된 우선순위 부여 시 기아 현상 발생 가능

다단계 피드백 큐(Multilevel Feedback Queue, MLFQ)
원리: 다단계 큐에 피드백 개념 추가하여 프로세스가 큐 간에 이동할 수 있도록 함
장점: 기아 현상 방지, 다양한 유형의 프로세스에 대한 유연한 스케줄링

컨텍스트 스위칭(Context Switching, 문맥 교환)
스케줄링 알고리즘에 의해 CPU를 사용하는 프로세스가 바뀔 때 현재 실행 중인 프로세스의 상태를 저장하고 다음에 실행될 프로세스의 저장된 상태를 로드하는 과정을 컨텍스트 스위칭이라고 합니다. 이는 오버헤드가 발생하지만 다중 프로그래밍, 시분할 시스템의 필수적인 부분입니다.



멀티스레드 컴퓨팅이란?
->
멀티스레드 컴퓨팅은 하나의 프로세스 내에서 여러 개의 스레드를 동시에 실행하여 작업을 병렬적으로 처리하는 프로그래밍 및 컴퓨팅 기법입니다.

프로세스와 스레드의 이해.
프로세스(Process): 운영체제로부터 독립적인 자원을 할당받아 실행되는 프로그램의 인스턴스, 각 프로세스는 독립적인 주소 공간을 가짐, 다른 프로세스와 자원을 직접 공유하지 않음
스레드(Thread): 한 프로세스 내에서 실행되는 가장 작은 실행 단위, 스레드는 프로세스의 코드, 데이터, 힙 영역을 공유하지만 자신만의 스택과 레지스터 집합을 가짐, 한 프로세스 내의 스레드들은 자원을 쉽게 공유할 수 있음

멀티스레드 컴퓨팅의 개념.
하나의 프로세스 안에 여러개의 스레드를 생성하고 스레드들이 각각 독립적인 실행 흐름을 가지면서도 프로세스의 자원을 공유하며 병렬적으로 작업을 수행하는 방식입니다.
UE5 예시: 게임 스레드, 렌더 스레드, 애니메이션 스레드, RHI 스레드, 물리 스레드 등

장점.
응답성 향상: 사용자의 응답만 처리하는 스레드 가능
자원 공유 및 효율성: 프로세스의 코드, 데이터, 힙 영역은 공유되므로 IPC보다 오버헤드가 적음
병렬성 활용: 멀티코어 프로세서 환경에서 여러 스레드가 동시에 다른 코어에서 실행될 수 있음, 처리속도 향상
경제성: 프로세스 생성 및 컨텍스트 스위칭 비용보다 스레드 생성 및 컨텍스트 스위칭 비용이 더 저렴함

단점 및 고려사항.
동기화 문제: 여러 스레드가 동일한 데이터를 동시에 접근하고 수정할 때 예상치 못하 결과가 발생할 수 있음, 방지하기 위해 뮤텍스, 세마포어, 락 등의 동기화 매커니즘을 사용
교착 상태(Deadlock): 2개 이상의 스레드가 서로가 점유하고 있는 자원을 기다리면서 무한히 대기하는 상태가 발생할 수 있음
프로그래밍 난이도 증가: 병렬성을 고려한 프로그래밍은 절차적 프로그래밍보다 복잡하고 디버깅도 어려움
성능 오버헤드: 과도한 스레드 생성은 컨텍스트 스위칭 오버헤드를 증가시켜 성능이 저하될 수 있음

멀티스레딩 모델.
사용자 수준 스레드 (User-Level Thread, ULT): 사용자 수준 라이브러리에 의해 스레드가 관리, 커널은 스레드의 존재를 모르고 프로세스 단위로 스케줄링, 한 스레드가 블록되면 전체 프로세스가 블록됨
커널 수준 스레드 (Kernel-Level Thread, KLT): 운영체제 커널이 직접 스레드를 관리하고 스케줄링, 한 스레드가 블록되어도 다른 스레드는 계속 실행 가능
하이브리드 모델: 사용자 수준 스레드를 커널 수준 스레드에 다대다로 매핑하는 방식



레이스 컨디션이란?
->
여러 개의 독립적인 실행 주체(프로세스 또는 스레드)가 공유 자원에 동시에 접근하여 조작할 때 접근하는 순서에 따라 결과값이 달라질 수 있는 상황을 의미하는

원인.
공유 자원 존재: 여러 스레드/프로세스가 접근하고 수정할 수 있는 공유된 데이터가 존재
동시 접근: 둘 이상의 스레드/프로세스가 공유 자원에 동시에 접근하려고 시도
경쟁 조건: 공유 자원에 대한 접근이 원자적이지 않을 때 발생

임계 영역(Critical Section).
레이스 컨디션이 발생하는 코드 영역, 둘 이상의 스레드/프로세스가 동시에 접근해서는 안되는 공유 자원 접근 코드 영역을 의미

레이스 컨디션 해결.
주된 해결방법은 동기화 매커니즘을 사용하여 임계 영역에 대한 상호 배제를 보장하는 것입니다.
뮤텍스: 한번에 하나의 스레드만이 임계 영역에 진입할 수 있도록 잠금을 제공
세마포어: 접근 가능한 자원의 수를 세는 카운터를 사용하여 여러개의 스레드가 공유 자원에 동시에 접근할 수 있도록 허용하지만 그 수를 제한
락: 특정 코드 블록이나 데이터에 대한 접근을 제어
모니터: 공유 데이터와 조작하는 프로시저들을 하나의 캡슐화된 객체로 포함시키고 한번에 하나의 스레드만 모니터의 프로시저를 실행할 수 있도록 보장
원자적 연산: 하드웨어 수준에서 단일 CPU 명령어로 실행되어 중간에 끼어들 수 없는 연산 사용



데드락이란?
->
데드락은 운영체제에서 여러 프로세스가 서로가 점유하고 있는 자원을 기다리느라 아무것도 진행하지 못하고 영원히 대기하는 상태를 의미합니다.

발생 조건.
아래 4가지 조건이 모두 충족되어야 데드락이 발생합니다.
상호 배제: 자원은 한번에 하나의 프로세스만 사용할 수 있어야 함
점유와 대기: 자원을 하나 이상 점유하고 있는 프로세스가 다른 프로세스가 점유하고 있는 자원을 얻기 위해 대기해야 함
비선점: 프로세스가 점유하고 있는 자원은 다른 프로세스에 의해 강제로 빼앗을 수 없음
순환 대기: 2개 이상의 프로세스가 자원 획득을 위해 원형으로 대기하는 상황 발생

데드락을 처리하기 위한 방법으로는 예방, 회피, 탐지와 회복, 무시 등이 있습니다.

데드락 예방.
데드락 발생 조건 4가지 중 하나를 사전에 불만족시키도록 시스템을 설계하는 방법
상호 배제 부정: 불가능하거나 비효율적 (모든 자원을 공유할 수는 없음)
점유와 대기 부정: 모든 자원을 한꺼번에 요청하거나 아무것도 획득하지 못하는 경우에만 시작(자원 활용률 저하, 기아 현상 발생 가능)
비선점 부정: 자원을 강제로 빼앗을 수 있도록 허용(불가능한 자원이 있을 수 있음)
순환 대기 부정: 모든 자원에 순서 부여하고 프로세스는 항상 순서대로 자원을 요청하도록 강제(자원 활용률 저하, 유연성 부족)
장점: 데드락이 절대 발생하지 않음
단점: 자원 활용률이 낮아지거나 시스템 성능 저하 가능, 모든 경우에 적용 어려움

데드락 회피.
시스템이 안전 상태를 유지할 수 있는 경우에만 자원을 할당하는 방법
시스템의 전체 자원 상태와 각 프로세스의 최대 자원 요구량을 미리 알고 있어야 함
은행원 알고리즘이 대표적
장점: 데드락 예방보다 자원 활용률이 높음
단점: 프로세스의 최대 자원 요구량을 미리 알아야함, 오버헤드가 큼, 자원 수가 고정되어야 함 등 비현실적인 가정이 많음

데드락 탐지.
시스템이 데드락 발생 여부를 주기적으로 검사하는 방법
자원 할당 그래프를 사용하여 사이클이 있는지 확인하는 방식
장점: 자원 활용률 높음, 특별한 제약 조건 없이 자원 할당 가능
단점: 데드락 탐지 오버헤드 있음, 탐지 후 해결해야 함

데드락 회복.
데드락이 탐지된 후에 시스템을 정상 상태로 되돌리는 방법
프로세스 강제 종료: 데드락에 연루된 프로세스 중 하나 이상을 강제로 종료
자원 선점: 데드락에 연루된 프로세스에게 자원을 빼앗아 다른 프로세스에게 할당
프로세스를 종료하거나 자원을 빼앗는 것은 비효율적, 작업 손실 발생 가능

데드락 무시.
데드락이 매우 드물게 발생하거나 발생하지 않는다고 가정하고 발생 시 시스템 재부팅 등 수동적으로 해결하는 방법
프로그래머에게 책임 전가: 데드락이 발생하지 않도록 코드 작성을 요구

운영체제는 데드락을 예방하거나 회피하는 전략을 적극적으로 사용하지 않습니다. 예방/회피 기법들이 너무 많은 제약과 오버헤드를 유발하여 시스템의 성능과 유연성을 저해하기 때문입니다.